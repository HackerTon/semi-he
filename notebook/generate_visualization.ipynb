{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.io.image import ImageReadMode, read_image, write_jpeg\n",
    "from torchvision.transforms.functional import resize\n",
    "from torchvision.transforms.v2 import Compose\n",
    "from torchvision.utils import draw_keypoints, draw_segmentation_masks\n",
    "\n",
    "from src.dataloader.transform import ImagenetNormalize, ToNormalized\n",
    "from src.model.model import UNETNetwork, UNETNetworkModi\n",
    "from src.utils.dirichlet_utils import (\n",
    "    combined_dirichlet,\n",
    "    convert_belief_mass_to_prediction,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_BASELINE_PATH = \"/mnt/storage/projects/semi-he/data/model/20241221_185129_tiger_baseline_500_bs16_pseudo/499_tiger_baseline_500_bs16_pseudo_model.pt\"\n",
    "MODEL_PROPOSED_PATH = \"/mnt/storage/projects/semi-he/data/model/20250109_184230_ukmtils_proposed_epoch500_bs16_pseudo/499_ukmtils_proposed_epoch500_bs16_pseudo_model.pt\"\n",
    "\n",
    "baseline_model = UNETNetwork(number_class=3)\n",
    "baseline_model.load_state_dict(torch.load(MODEL_BASELINE_PATH))\n",
    "baseline_model.cuda()\n",
    "baseline_model.eval()\n",
    "proposed_model = UNETNetworkModi(number_class=3)\n",
    "proposed_model.load_state_dict(torch.load(MODEL_PROPOSED_PATH))\n",
    "proposed_model.cuda()\n",
    "proposed_model.eval()\n",
    "preprocessor = Compose([ToNormalized(), ImagenetNormalize()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_baseline(\n",
    "    prediction: torch.Tensor,\n",
    "    original_size,\n",
    "):\n",
    "    final_prediction = prediction.sigmoid()\n",
    "    resized_prediction = resize(final_prediction, original_size)\n",
    "    colored_prediction = resized_prediction.argmax(1)\n",
    "    return colored_prediction\n",
    "\n",
    "\n",
    "def generate_dirichlet(\n",
    "    prediction: torch.Tensor,\n",
    "    original_size,\n",
    "):\n",
    "    output_belief, output_uncertainty = combined_dirichlet(\n",
    "        prediction[0].relu(),\n",
    "        prediction[1].relu(),\n",
    "    )\n",
    "    final_prediction = convert_belief_mass_to_prediction(\n",
    "        output_belief,\n",
    "        output_uncertainty,\n",
    "    )\n",
    "    resized_prediction = resize(final_prediction, original_size)\n",
    "    colored_prediction = resized_prediction.argmax(1)\n",
    "    return colored_prediction\n",
    "\n",
    "\n",
    "def convert_to_standard_color(\n",
    "    argmax_prediction: torch.Tensor,\n",
    "    original_image,\n",
    "    mapping=None,\n",
    "    alpha=0.2,\n",
    "):\n",
    "    if mapping is None:\n",
    "        masks = torch.stack(\n",
    "            [\n",
    "                argmax_prediction[0] == 0,\n",
    "                argmax_prediction[0] == 1,\n",
    "                argmax_prediction[0] == 2,\n",
    "            ],\n",
    "        )\n",
    "    else:\n",
    "        masks = torch.stack(\n",
    "            [\n",
    "                argmax_prediction[0] == mapping[0],\n",
    "                argmax_prediction[0] == mapping[1],\n",
    "                argmax_prediction[0] == mapping[2],\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    colors = [(0, 0, 0), (255, 0, 0), (0, 255, 0)]\n",
    "    return draw_segmentation_masks(\n",
    "        original_image,\n",
    "        masks,\n",
    "        alpha=alpha,\n",
    "        colors=colors,\n",
    "    )\n",
    "\n",
    "\n",
    "def write_images(\n",
    "    images,\n",
    "    directory: Path,\n",
    "    index,\n",
    "):\n",
    "    image_paths = [\n",
    "        directory.joinpath(f\"{index}_image.jpg\"),\n",
    "        directory.joinpath(f\"{index}_proposed.jpg\"),\n",
    "        directory.joinpath(f\"{index}_baseline.jpg\"),\n",
    "        directory.joinpath(f\"{index}_label.jpg\"),\n",
    "    ]\n",
    "    for image, image_path in zip(images, image_paths):\n",
    "        write_jpeg(image, str(image_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Visualisation for UKMTIls dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_BASELINE_PATH = \"/mnt/storage/projects/semi-he/data/model/20241221_185129_tiger_baseline_500_bs16_pseudo/499_tiger_baseline_500_bs16_pseudo_model.pt\"\n",
    "MODEL_PROPOSED_PATH = \"/mnt/storage/projects/semi-he/data/model/20250109_184230_ukmtils_proposed_epoch500_bs16_pseudo/499_ukmtils_proposed_epoch500_bs16_pseudo_model.pt\"\n",
    "\n",
    "baseline_model = UNETNetwork(number_class=3)\n",
    "baseline_model.load_state_dict(torch.load(MODEL_BASELINE_PATH))\n",
    "baseline_model.cuda()\n",
    "baseline_model.eval()\n",
    "proposed_model = UNETNetworkModi(number_class=3)\n",
    "proposed_model.load_state_dict(torch.load(MODEL_PROPOSED_PATH))\n",
    "proposed_model.cuda()\n",
    "proposed_model.eval()\n",
    "preprocessor = Compose([ToNormalized(), ImagenetNormalize()])\n",
    "\n",
    "# Dataset Definition\n",
    "test_image = Path(\"/mnt/storage/Dataset130_ukmtils/imagesTs/\")\n",
    "images = [x for x in test_image.glob(\"*.png\")]\n",
    "\n",
    "DIRECTORY_NAME = \"UKMTILS_SAMPLES\"\n",
    "num_samples = 20\n",
    "directory = Path(DIRECTORY_NAME)\n",
    "if not directory.exists():\n",
    "    directory.mkdir()\n",
    "# plt.figure(figsize=(16, 5 * num_samples), dpi=300)\n",
    "# plt.tight_layout()\n",
    "\n",
    "for i, image_path in enumerate(images):\n",
    "    label_path = str(image_path).replace(\"_0000\", \"\").replace(\"images\", \"labels\")\n",
    "    image = read_image(str(image_path)).unsqueeze(0)\n",
    "    label = read_image(label_path, ImageReadMode.GRAY).unsqueeze(0)\n",
    "\n",
    "    processed_image, mask = preprocessor(image.cuda(), label.cuda())\n",
    "\n",
    "    processed_image = resize(processed_image, [1024, 1024])\n",
    "    with torch.no_grad():\n",
    "        prediction_1 = baseline_model(processed_image)\n",
    "        prediction_2 = proposed_model(processed_image)\n",
    "\n",
    "    baseline_prediction = generate_baseline(prediction_1, image.shape[2:])\n",
    "    proposed_prediction = generate_dirichlet(prediction_2, image.shape[2:])\n",
    "    baseline_prediction = convert_to_standard_color(baseline_prediction, image[0])\n",
    "    proposed_prediction = convert_to_standard_color(proposed_prediction, image[0])\n",
    "    label = convert_to_standard_color(label[0], image[0])\n",
    "\n",
    "    images = [\n",
    "        image[0],\n",
    "        proposed_prediction.cpu(),\n",
    "        baseline_prediction.cpu(),\n",
    "        label.cpu(),\n",
    "    ]\n",
    "\n",
    "    write_images(images, directory, i)\n",
    "\n",
    "    # plt.subplot(num_samples, 3, 1 + i * 3)\n",
    "    # plt.title(\"Image\")\n",
    "    # plt.imshow(image[0].permute([1, 2, 0]))\n",
    "    # plt.subplot(num_samples, 3, 2 + i * 3)\n",
    "    # plt.title(\"Baseline\")\n",
    "    # plt.imshow(image[0].permute([1, 2, 0]), alpha=1.0)\n",
    "    # plt.imshow(model_1_color_prediction.cpu(), alpha=0.2)\n",
    "    # plt.subplot(num_samples, 3, 3 + i * 3)\n",
    "    # plt.title(\"Proposed\")\n",
    "    # plt.imshow(image[0].permute([1, 2, 0]), alpha=1.0)\n",
    "    # plt.imshow(model_2_color_prediction.cpu(), alpha=0.2)\n",
    "    # plt.subplot(num_samples, 4, 4 + i * 3)\n",
    "    # plt.title(\"Label\")\n",
    "    # plt.imshow(image[0].permute([1, 2, 0]), alpha=1.0)\n",
    "    # plt.imshow(label.cpu(), alpha=0.2)\n",
    "\n",
    "    if i == (num_samples - 1):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Visualisation for Ocelot dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_BASELINE_PATH = \"/mnt/storage/projects/semi-he/data/model/20250110_012619_ocelot_baseline_epoch500_bs16_pseudo/499_ocelot_baseline_epoch500_bs16_pseudo_model.pt\"\n",
    "MODEL_PROPOSED_PATH = \"/mnt/storage/projects/semi-he/data/model/20250110_225854_ocelot_proposed_epoch500_bs16_pseudo/499_ocelot_proposed_epoch500_bs16_pseudo_model.pt\"\n",
    "\n",
    "baseline_model = UNETNetwork(number_class=3)\n",
    "baseline_model.load_state_dict(torch.load(MODEL_BASELINE_PATH))\n",
    "baseline_model.cuda()\n",
    "baseline_model.eval()\n",
    "proposed_model = UNETNetworkModi(number_class=3)\n",
    "proposed_model.load_state_dict(torch.load(MODEL_PROPOSED_PATH))\n",
    "proposed_model.cuda()\n",
    "proposed_model.eval()\n",
    "preprocessor = Compose([ToNormalized(), ImagenetNormalize()])\n",
    "\n",
    "# Dataset Definition\n",
    "test_image = Path(\"/mnt/storage/ocelot2023_v1.0.1/images/test/tissue/\")\n",
    "images = [x for x in test_image.glob(\"*.jpg\")]\n",
    "\n",
    "DIRECTORY_NAME = \"OCELOT\"\n",
    "num_samples = 20\n",
    "directory = Path(DIRECTORY_NAME)\n",
    "if not directory.exists():\n",
    "    directory.mkdir()\n",
    "# plt.figure(figsize=(16, 5 * num_samples), dpi=300)\n",
    "# plt.tight_layout()\n",
    "\n",
    "for i, image_path in enumerate(images):\n",
    "    label_path = str(image_path).replace(\"images\", \"annotations\").replace(\"jpg\", \"png\")\n",
    "    image = read_image(str(image_path)).unsqueeze(0)\n",
    "    label = read_image(label_path, ImageReadMode.GRAY).unsqueeze(0)\n",
    "\n",
    "    processed_image, mask = preprocessor(image.cuda(), label.cuda())\n",
    "\n",
    "    processed_image = resize(processed_image, [1024, 1024])\n",
    "    with torch.no_grad():\n",
    "        prediction_1 = baseline_model(processed_image)\n",
    "        prediction_2 = proposed_model(processed_image)\n",
    "\n",
    "    baseline_prediction = generate_baseline(prediction_1, image.shape[2:])\n",
    "    proposed_prediction = generate_dirichlet(prediction_2, image.shape[2:])\n",
    "    baseline_prediction = convert_to_standard_color(\n",
    "        baseline_prediction, image[0], alpha=0.3\n",
    "    )\n",
    "    proposed_prediction = convert_to_standard_color(\n",
    "        proposed_prediction, image[0], alpha=0.3\n",
    "    )\n",
    "    label = convert_to_standard_color(label[0], image[0], [1, 2, 255], alpha=0.3)\n",
    "    images = [\n",
    "        image[0],\n",
    "        proposed_prediction.cpu(),\n",
    "        baseline_prediction.cpu(),\n",
    "        label.cpu(),\n",
    "    ]\n",
    "\n",
    "    write_images(images, directory, i)\n",
    "\n",
    "    # plt.subplot(num_samples, 3, 1 + i * 3)\n",
    "    # plt.title(\"Image\")\n",
    "    # plt.imshow(image[0].permute([1, 2, 0]))\n",
    "    # plt.subplot(num_samples, 3, 2 + i * 3)\n",
    "    # plt.title(\"Baseline\")\n",
    "    # plt.imshow(image[0].permute([1, 2, 0]), alpha=1.0)\n",
    "    # plt.imshow(model_1_color_prediction.cpu(), alpha=0.2)\n",
    "    # plt.subplot(num_samples, 3, 3 + i * 3)\n",
    "    # plt.title(\"Proposed\")\n",
    "    # plt.imshow(image[0].permute([1, 2, 0]), alpha=1.0)\n",
    "    # plt.imshow(model_2_color_prediction.cpu(), alpha=0.2)\n",
    "    # plt.subplot(num_samples, 4, 4 + i * 3)\n",
    "    # plt.title(\"Label\")\n",
    "    # plt.imshow(image[0].permute([1, 2, 0]), alpha=1.0)\n",
    "    # plt.imshow(label.cpu(), alpha=0.2)\n",
    "\n",
    "    if i == (num_samples - 1):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
