{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "from shutil import rmtree\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from nvidia.dali import fn, pipeline_def\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.io.image import ImageReadMode, read_image, write_png\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms.functional import InterpolationMode, resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OcelotDataset(Dataset):\n",
    "    def __init__(self, directory_path: str):\n",
    "        self.directory = Path(directory_path)\n",
    "        self._initialize_dataset()\n",
    "\n",
    "    def _initialize_dataset(self):\n",
    "        image_length = len(list(self.directory.glob(\"images/train/tissue/*.jpg\")))\n",
    "        label_length = len(list(self.directory.glob(\"annotations/train/tissue/*.png\")))\n",
    "        uncertainty_length = len(list(self.directory.glob(\"*_uncertainty.bin\")))\n",
    "\n",
    "        if image_length != label_length != uncertainty_length:\n",
    "            raise Exception(\n",
    "                f\"Image length {image_length} != label length {label_length} != uncertainty_length {uncertainty_length}\"\n",
    "            )\n",
    "\n",
    "        self.dataset_length = image_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_length\n",
    "\n",
    "    def get_mask(self, label):\n",
    "        return (\n",
    "            torch.concatenate(\n",
    "                [\n",
    "                    (label == 1),  # BACKGROUND class\n",
    "                    (label == 2),  # CANCER class\n",
    "                    (label == 255),  # UNKNOWN class\n",
    "                ]\n",
    "            )\n",
    "            * 255\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filled_index = str(index + 1).zfill(3)\n",
    "        image_path = str(\n",
    "            self.directory.joinpath(f\"images/train/tissue/{filled_index}.jpg\")\n",
    "        )\n",
    "        label_path = str(\n",
    "            self.directory.joinpath(f\"annotations/train/tissue/{filled_index}.png\")\n",
    "        )\n",
    "        image = read_image(image_path, ImageReadMode.RGB)\n",
    "        label = read_image(label_path, ImageReadMode.GRAY)\n",
    "        label = self.get_mask(label).to(torch.uint8)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Critical error when building pipeline:\nError in CPU operator `nvidia.dali.fn.readers.file`,\nwhich was used in the pipeline definition with the following traceback:\n\n  File \"/tmp/ipykernel_5629/2598378851.py\", line 6, in pipe\n    image_files, label_files = fn.readers.file(file_root=directory)\n\nencountered:\n\nAssert on \"SizeImpl() > 0\" failed: No files found.\nC++ context: [/opt/dali/dali/operators/reader/loader/file_label_loader.h:192] \nCurrent pipeline object is no longer valid.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m images\n\u001b[1;32m     12\u001b[0m pipe \u001b[38;5;241m=\u001b[39m pipe()\n\u001b[0;32m---> 13\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m data \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mrun()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(data)\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.12/site-packages/nvidia/dali/pipeline.py:1060\u001b[0m, in \u001b[0;36mPipeline.build\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_pipeline_backend()\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_pipe_pool_dependency()\n\u001b[0;32m-> 1060\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_build_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restore_state_from_checkpoint()\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_built \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Critical error when building pipeline:\nError in CPU operator `nvidia.dali.fn.readers.file`,\nwhich was used in the pipeline definition with the following traceback:\n\n  File \"/tmp/ipykernel_5629/2598378851.py\", line 6, in pipe\n    image_files, label_files = fn.readers.file(file_root=directory)\n\nencountered:\n\nAssert on \"SizeImpl() > 0\" failed: No files found.\nC++ context: [/opt/dali/dali/operators/reader/loader/file_label_loader.h:192] \nCurrent pipeline object is no longer valid."
     ]
    }
   ],
   "source": [
    "directory = \"/mnt/storage/ocelot2023_v1.0.1/images/train/tissue/\"\n",
    "\n",
    "\n",
    "@pipeline_def(batch_size=8, num_threads=4, device_id=0)\n",
    "def pipe():\n",
    "    image_files, label_files = fn.external_source()\n",
    "    images = fn.decoders.image(image_files, device=\"cpu\")\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "pipe = pipe()\n",
    "pipe.build()\n",
    "data = pipe.run()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = dataset[0]\n",
    "\n",
    "plt.figure(figsize=(9, 16))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(image.permute([1, 2, 0]))\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(label.permute([1, 2, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tensor = torch.rand([128, 8, 1024, 1024], device=\"cuda\")\n",
    "np.save(\"../data.npy\", random_tensor.cpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
